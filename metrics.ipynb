{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        self.category_mapping = {\n",
    "            # Restaurant categories\n",
    "            'Afghan Restaurant': 'Food',\n",
    "            'African Restaurant': 'Food',\n",
    "            'American Restaurant': 'Food',\n",
    "            'Arepa Restaurant': 'Food',\n",
    "            'Argentinian Restaurant': 'Food',\n",
    "            'Asian Restaurant': 'Food',\n",
    "            'Australian Restaurant': 'Food',\n",
    "            'BBQ Joint': 'Food',\n",
    "            'Brazilian Restaurant': 'Food',\n",
    "            'Burger Joint': 'Food',\n",
    "            'Burrito Place': 'Food',\n",
    "            'Caribbean Restaurant': 'Food',\n",
    "            'Chinese Restaurant': 'Food',\n",
    "            'Cuban Restaurant': 'Food',\n",
    "            'Dim Sum Restaurant': 'Food',\n",
    "            'Diner': 'Food',\n",
    "            'Dumpling Restaurant': 'Food',\n",
    "            'Eastern European Restaurant': 'Food',\n",
    "            'Ethiopian Restaurant': 'Food',\n",
    "            'Falafel Restaurant': 'Food',\n",
    "            'Fast Food Restaurant': 'Food',\n",
    "            'Filipino Restaurant': 'Food',\n",
    "            'Fish & Chips Shop': 'Food',\n",
    "            'French Restaurant': 'Food',\n",
    "            'Fried Chicken Joint': 'Food',\n",
    "            'German Restaurant': 'Food',\n",
    "            'Greek Restaurant': 'Food',\n",
    "            'Hot Dog Joint': 'Food',\n",
    "            'Indian Restaurant': 'Food',\n",
    "            'Italian Restaurant': 'Food',\n",
    "            'Japanese Restaurant': 'Food',\n",
    "            'Korean Restaurant': 'Food',\n",
    "            'Latin American Restaurant': 'Food',\n",
    "            'Malaysian Restaurant': 'Food',\n",
    "            'Mediterranean Restaurant': 'Food',\n",
    "            'Mexican Restaurant': 'Food',\n",
    "            'Middle Eastern Restaurant': 'Food',\n",
    "            'Molecular Gastronomy Restaurant': 'Food',\n",
    "            'Moroccan Restaurant': 'Food',\n",
    "            'Peruvian Restaurant': 'Food',\n",
    "            'Pizza Place': 'Food',\n",
    "            'Portuguese Restaurant': 'Food',\n",
    "            'Ramen /  Noodle House': 'Food',\n",
    "            'Restaurant': 'Food',\n",
    "            'Seafood Restaurant': 'Food',\n",
    "            'South American Restaurant': 'Food',\n",
    "            'Southern / Soul Food Restaurant': 'Food',\n",
    "            'Spanish Restaurant': 'Food',\n",
    "            'Steakhouse': 'Food',\n",
    "            'Sushi Restaurant': 'Food',\n",
    "            'Swiss Restaurant': 'Food',\n",
    "            'Taco Place': 'Food',\n",
    "            'Thai Restaurant': 'Food',\n",
    "            'Turkish Restaurant': 'Food',\n",
    "            'Vegetarian / Vegan Restaurant': 'Food',\n",
    "            'Vietnamese Restaurant': 'Food',\n",
    "            'Wings Joint': 'Food',\n",
    "            \n",
    "            # Shops and services\n",
    "            'Antique Shop': 'Shop & Service',\n",
    "            'Arts & Crafts Store': 'Shop & Service',\n",
    "            'Automotive Shop': 'Shop & Service',\n",
    "            'Bike Shop': 'Shop & Service',\n",
    "            'Board Shop': 'Shop & Service',\n",
    "            'Bookstore': 'Shop & Service',\n",
    "            'Bridal Shop': 'Shop & Service',\n",
    "            'Camera Store': 'Shop & Service',\n",
    "            'Clothing Store': 'Shop & Service',\n",
    "            'Cosmetics Shop': 'Shop & Service',\n",
    "            'Department Store': 'Shop & Service',\n",
    "            'Electronics Store': 'Shop & Service',\n",
    "            'Flower Shop': 'Shop & Service',\n",
    "            'Food & Drink Shop': 'Shop & Service',\n",
    "            'Furniture / Home Store': 'Shop & Service',\n",
    "            'Gift Shop': 'Shop & Service',\n",
    "            'Hardware Store': 'Shop & Service',\n",
    "            'Hobby Shop': 'Shop & Service',\n",
    "            'Jewelry Store': 'Shop & Service',\n",
    "            'Mall': 'Shop & Service',\n",
    "            'Market': 'Shop & Service',\n",
    "            'Miscellaneous Shop': 'Shop & Service',\n",
    "            'Mobile Phone Shop': 'Shop & Service',\n",
    "            'Paper / Office Supplies Store': 'Shop & Service',\n",
    "            'Pet Store': 'Shop & Service',\n",
    "            'Record Shop': 'Shop & Service',\n",
    "            'Sporting Goods Shop': 'Shop & Service',\n",
    "            'Thrift / Vintage Store': 'Shop & Service',\n",
    "            'Toy / Game Store': 'Shop & Service',\n",
    "            'Video Game Store': 'Shop & Service',\n",
    "            'Video Store': 'Shop & Service',\n",
    "            \n",
    "            # Transportation related\n",
    "            'Airport': 'Travel & Transport',\n",
    "            'Bus Station': 'Travel & Transport',\n",
    "            'Ferry': 'Travel & Transport',\n",
    "            'Light Rail': 'Travel & Transport',\n",
    "            'Parking': 'Travel & Transport',\n",
    "            'Rental Car Location': 'Travel & Transport',\n",
    "            'Rest Area': 'Travel & Transport',\n",
    "            'Road': 'Travel & Transport',\n",
    "            'Subway': 'Travel & Transport',\n",
    "            'Train Station': 'Travel & Transport',\n",
    "            'Travel Lounge': 'Travel & Transport',\n",
    "            \n",
    "            # Outdoor recreation\n",
    "            'Beach': 'Outdoors & Recreation',\n",
    "            'Bridge': 'Outdoors & Recreation',\n",
    "            'Campground': 'Outdoors & Recreation',\n",
    "            'Garden': 'Outdoors & Recreation',\n",
    "            'Harbor / Marina': 'Outdoors & Recreation',\n",
    "            'Other Great Outdoors': 'Outdoors & Recreation',\n",
    "            'Park': 'Outdoors & Recreation',\n",
    "            'Playground': 'Outdoors & Recreation',\n",
    "            'Plaza': 'Outdoors & Recreation',\n",
    "            'Pool': 'Outdoors & Recreation',\n",
    "            'River': 'Outdoors & Recreation',\n",
    "            'Scenic Lookout': 'Outdoors & Recreation',\n",
    "            'Sculpture Garden': 'Outdoors & Recreation',\n",
    "            'Ski Area': 'Outdoors & Recreation',\n",
    "            \n",
    "            # Arts and entertainment\n",
    "            'Aquarium': 'Arts & Entertainment',\n",
    "            'Arcade': 'Arts & Entertainment',\n",
    "            'Art Gallery': 'Arts & Entertainment',\n",
    "            'Art Museum': 'Arts & Entertainment',\n",
    "            'Casino': 'Arts & Entertainment',\n",
    "            'Comedy Club': 'Arts & Entertainment',\n",
    "            'Concert Hall': 'Arts & Entertainment',\n",
    "            'Movie Theater': 'Arts & Entertainment',\n",
    "            'Museum': 'Arts & Entertainment',\n",
    "            'Music Venue': 'Arts & Entertainment',\n",
    "            'Performing Arts Venue': 'Arts & Entertainment',\n",
    "            'Stadium': 'Arts & Entertainment',\n",
    "            'Theater': 'Arts & Entertainment',\n",
    "            \n",
    "            # Professional places\n",
    "            'Bank': 'Professional & Workplace',\n",
    "            'Building': 'Professional & Workplace',\n",
    "            'Convention Center': 'Professional & Workplace',\n",
    "            'Government Building': 'Professional & Workplace',\n",
    "            'Medical Center': 'Professional & Workplace',\n",
    "            'Office': 'Professional & Workplace',\n",
    "            'Post Office': 'Professional & Workplace',\n",
    "            \n",
    "            # Residential\n",
    "            'Home (private)': 'Residence',\n",
    "            'Housing Development': 'Residence',\n",
    "            'Residential Building (Apartment / Condo)': 'Residence',\n",
    "            \n",
    "            # Educational institutions\n",
    "            'College Academic Building': 'College & University',\n",
    "            'College Stadium': 'College & University',\n",
    "            'College Theater': 'College & University',\n",
    "            'Community College': 'College & University',\n",
    "            'Elementary School': 'College & University',\n",
    "            'High School': 'College & University',\n",
    "            'Law School': 'College & University',\n",
    "            'Library': 'College & University',\n",
    "            'Medical School': 'College & University',\n",
    "            'Middle School': 'College & University',\n",
    "            'Music School': 'College & University',\n",
    "            'School': 'College & University',\n",
    "            'Trade School': 'College & University',\n",
    "            'University': 'College & University',\n",
    "            \n",
    "            # Nightlife spots\n",
    "            'Bar': 'Nightlife Spot',\n",
    "            'Beer Garden': 'Nightlife Spot',\n",
    "            'Night Club': 'Nightlife Spot',\n",
    "            'Other Nightlife': 'Nightlife Spot',\n",
    "            \n",
    "            # Event venues\n",
    "            'Event Space': 'Event',\n",
    "            'Fair': 'Event',\n",
    "            'Festival': 'Event'\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real dataset statistics:\n",
      "  Number of trajectories: 47322\n",
      "  Total points: 171040\n",
      "  Average points per trajectory: 3.61\n",
      "  Average movement distance: 3.18 km\n",
      "  Most common activity types:\n",
      "    - Unknown: 28238 times (16.5%)\n",
      "    - Shop & Service: 28210 times (16.5%)\n",
      "    - Travel & Transport: 25732 times (15.0%)\n",
      "    - Food: 20123 times (11.8%)\n",
      "    - Professional & Workplace: 19971 times (11.7%)\n",
      "\n",
      "Generated dataset statistics:\n",
      "  Number of trajectories: 1073\n",
      "  Total points: 18856\n",
      "  Average points per trajectory: 17.57\n",
      "  Average movement distance: 2.60 km\n",
      "  Most common activity types:\n",
      "    - Food: 3754 times (19.9%)\n",
      "    - Shop & Service: 3300 times (17.5%)\n",
      "    - Unknown: 3294 times (17.5%)\n",
      "    - Nightlife Spot: 1797 times (9.5%)\n",
      "    - Professional & Workplace: 1557 times (8.3%)\n",
      "\n",
      "\n",
      "Trajectory consistency analysis results (Jensen-Shannon Divergence):\n",
      "1. Step distance (SD): 0.040\n",
      "2. Step interval (SI): 0.162\n",
      "3. Daily activity routine distribution (DARD): 0.021\n",
      "4. Spatial-temporal visits distribution (STVD): 0.038\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "from datetime import datetime, timedelta\n",
    "from math import radians, sin, cos, asin, sqrt\n",
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "# Geographic distance calculation function (unit: kilometers)\n",
    "def geodistance(lon1, lat1, lon2, lat2):\n",
    "    lon1, lat1, lon2, lat2 = map(radians, [float(lon1), float(lat1), float(lon2), float(lat2)])\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\n",
    "    distance = 2 * asin(sqrt(a)) * 6371\n",
    "    return distance  # Return distance in kilometers\n",
    "\n",
    "# JSD calculation function\n",
    "def js_divergence(p, q):\n",
    "    p = np.array(p, dtype=float)\n",
    "    q = np.array(q, dtype=float)\n",
    "    \n",
    "    # Avoid division by zero\n",
    "    p = p / (p.sum() + 1e-9)\n",
    "    q = q / (q.sum() + 1e-9)\n",
    "    \n",
    "    m = (p + q) / 2\n",
    "    return 0.5 * scipy.stats.entropy(p, m) + 0.5 * scipy.stats.entropy(q, m)\n",
    "\n",
    "# Trajectory analysis class\n",
    "class TrajectoryAnalyzer:\n",
    "    def __init__(self, grid_size=0.01, lat_range=(40.5, 40.9), lon_range=(-74.25, -73.7)):\n",
    "        self.grid_size = grid_size\n",
    "        self.lat_min, self.lat_max = lat_range\n",
    "        self.lon_min, self.lon_max = lon_range\n",
    "        self.n_lat = int((self.lat_max - self.lat_min) / grid_size) + 1\n",
    "        self.n_lon = int((self.lon_max - self.lon_min) / grid_size) + 1\n",
    "        self.grid_total = self.n_lat * self.n_lon\n",
    "        self.time_bins = 144  # 24 hours * 6 (10-minute intervals)\n",
    "        \n",
    "        # Activity type standardization mapping\n",
    "        self.category_keywords = {\n",
    "            'Food': [\n",
    "                'afghan', 'african', 'american', 'arepa', 'argentinian',\n",
    "                'asian', 'australian', 'bbq', 'brazilian', 'burger', 'burrito',\n",
    "                'caribbean', 'chinese', 'cuban', 'dim sum', 'diner', 'dumpling',\n",
    "                'eastern european', 'ethiopian', 'falafel', 'fast food', 'filipino',\n",
    "                'fish & chips', 'french', 'fried chicken', 'german', 'greek', 'hot dog',\n",
    "                'indian', 'italian', 'japanese', 'korean', 'latin american', 'malaysian',\n",
    "                'mediterranean', 'mexican', 'middle eastern', 'molecular gastronomy',\n",
    "                'moroccan', 'peruvian', 'pizza', 'portuguese', 'ramen', 'noodle',\n",
    "                'restaurant', 'seafood', 'south american', 'southern', 'soul food',\n",
    "                'spanish', 'steakhouse', 'sushi', 'swiss', 'taco', 'thai', 'turkish',\n",
    "                'vegetarian', 'vegan', 'vietnamese', 'wings'\n",
    "            ],\n",
    "            'Shop & Service': [\n",
    "                'antique', 'arts and crafts', 'automotive', 'bike', 'board',\n",
    "                'bookstore', 'bridal', 'camera', 'clothing', 'cosmetics', 'department store',\n",
    "                'electronics', 'flower', 'food & drink', 'furniture', 'home store',\n",
    "                'gift shop', 'hardware', 'hobby', 'jewelry', 'mall', 'market',\n",
    "                'miscellaneous shop', 'mobile phone', 'paper', 'office supplies',\n",
    "                'pet store', 'record', 'sporting goods', 'thrift', 'vintage', 'toy',\n",
    "                'game store', 'video game', 'video store', 'shop', 'store', 'goods'\n",
    "            ],\n",
    "            'Travel & Transport': [\n",
    "                'airport', 'bus', 'ferry', 'light rail', 'parking',\n",
    "                'car', 'rest area', 'road', 'subway', 'train', 'travel'\n",
    "            ],\n",
    "            'Outdoors & Recreation': [\n",
    "                'beach', 'bridge', 'campground', 'garden', 'harbor', 'marina',\n",
    "                'great outdoors', 'park', 'playground', 'plaza', 'pool', 'river',\n",
    "                'scenic lookout', 'sculpture garden', 'ski area'\n",
    "            ],\n",
    "            'Arts & Entertainment': [\n",
    "                'aquarium', 'arcade', 'art gallery', 'art museum', 'casino',\n",
    "                'comedy club', 'concert hall', 'movie theater', 'museum', 'music venue',\n",
    "                'performing arts', 'stadium', 'theater', 'gallery', 'art', 'club'\n",
    "            ],\n",
    "            'Professional & Workplace': [\n",
    "                'bank', 'building', 'convention center', 'government', 'medical center',\n",
    "                'office', 'post office', 'work'\n",
    "            ],\n",
    "            'Residence': [\n",
    "                'home', 'private', 'housing', 'residential',\n",
    "                'apartment', 'condo'\n",
    "            ],\n",
    "            'College & University': [\n",
    "                'college', 'academic', 'stadium', 'theater', 'community college',\n",
    "                'school', 'library', 'school', 'university'\n",
    "            ],\n",
    "            'Nightlife Spot': [\n",
    "                'bar', 'beer garden', 'night club', 'nightlife'\n",
    "            ],\n",
    "            'Event': [\n",
    "                'event space', 'fair', 'festival'\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        # Activity type ID mapping\n",
    "        self.activity_map = {\n",
    "            'Food': 0, \n",
    "            'Shop & Service': 1,\n",
    "            'Travel & Transport': 2, \n",
    "            'Outdoors & Recreation': 3, \n",
    "            'Arts & Entertainment': 4, \n",
    "            'Professional & Workplace': 5,\n",
    "            'Residence': 6,\n",
    "            'College & University': 7, \n",
    "            'Nightlife Spot': 8, \n",
    "            'Event': 9,\n",
    "            'Unknown': 10\n",
    "        }\n",
    "    \n",
    "    def parse_real_time(self, time_str):\n",
    "        \"\"\"Parse time format for real data (Tue Apr 03 18:00:09 +0000 2012)\"\"\"\n",
    "        try:\n",
    "            dt = datetime.strptime(time_str, '%a %b %d %H:%M:%S %z %Y')\n",
    "            return dt\n",
    "        except ValueError:\n",
    "            print(f\"Cannot parse real data time string: {time_str}\")\n",
    "            return None\n",
    "    \n",
    "    def parse_gen_time(self, time_str):\n",
    "        \"\"\"Parse time format for generated data (2025/5/28 8:00)\"\"\"\n",
    "        try:\n",
    "            dt = datetime.strptime(time_str, '%Y/%m/%d %H:%M')\n",
    "            return dt\n",
    "        except ValueError:\n",
    "            try:\n",
    "                dt = datetime.strptime(time_str, '%Y-%m-%d %H:%M:%S')\n",
    "                return dt\n",
    "            except ValueError:\n",
    "                print(f\"Cannot parse generated data time string: {time_str}\")\n",
    "                return None\n",
    "    \n",
    "    def time_to_bin(self, dt):\n",
    "        \"\"\"Convert time to time slot index (10-minute intervals)\"\"\"\n",
    "        total_minutes = dt.hour * 60 + dt.minute\n",
    "        return min(int(total_minutes // 10), self.time_bins - 1)\n",
    "    \n",
    "    def latlon_to_grid(self, lat, lon):\n",
    "        \"\"\"Convert latitude/longitude to grid index\"\"\"\n",
    "        if not (self.lat_min <= lat <= self.lat_max and self.lon_min <= lon <= self.lon_max):\n",
    "            return -1  # Out of range\n",
    "        \n",
    "        lat_idx = int((lat - self.lat_min) / self.grid_size)\n",
    "        lon_idx = int((lon - self.lon_min) / self.grid_size)\n",
    "        return min(lat_idx * self.n_lon + lon_idx, self.grid_total - 1)\n",
    "    \n",
    "    # def normalize_category(self, category):\n",
    "    #     \"\"\"Standardize various category names to main categories\"\"\"\n",
    "    #     return self.category_mapping.get(category, category)\n",
    "    def normalize_category(self, category):\n",
    "        \"\"\"Standardize category names using keyword matching\"\"\"\n",
    "        if not isinstance(category, str):\n",
    "            return 'Unknown'\n",
    "        \n",
    "        category_lower = category.lower()\n",
    "        for main_category, keywords in self.category_keywords.items():\n",
    "            for keyword in keywords:\n",
    "                if keyword in category_lower:\n",
    "                    return main_category\n",
    "        return 'Unknown'\n",
    "    \n",
    "    def get_activity_id(self, category):\n",
    "        \"\"\"Get ID for activity type\"\"\"\n",
    "        normalized_category = self.normalize_category(category)\n",
    "        return self.activity_map.get(normalized_category, self.activity_map['Unknown'])\n",
    "    \n",
    "    def analyze_real_trajectories(self, real_df):\n",
    "        \"\"\"Analyze real trajectory data\"\"\"\n",
    "        traj_data = []\n",
    "        \n",
    "        # Group trajectories by user and date\n",
    "        real_df['date'] = real_df['utcTimestamp'].apply(\n",
    "            lambda x: self.parse_real_time(x).strftime('%Y-%m-%d') if self.parse_real_time(x) else None\n",
    "        )\n",
    "        \n",
    "        # Remove records with invalid dates\n",
    "        real_df = real_df.dropna(subset=['date'])\n",
    "        \n",
    "        for (user_id, date), group in real_df.groupby(['userId', 'date']):\n",
    "            user_traj = []\n",
    "            group = group.sort_values('utcTimestamp')\n",
    "            \n",
    "            for _, row in group.iterrows():\n",
    "                dt = self.parse_real_time(row['utcTimestamp'])\n",
    "                if dt is None:\n",
    "                    continue\n",
    "                \n",
    "                grid_idx = self.latlon_to_grid(row['latitude'], row['longitude'])\n",
    "                \n",
    "                if grid_idx >= 0:\n",
    "                    # Store actual time instead of time slot\n",
    "                    act_id = self.get_activity_id(row['venueCategory'])\n",
    "                    user_traj.append([dt, act_id, [row['latitude'], row['longitude']]])\n",
    "            \n",
    "            if len(user_traj) > 1:\n",
    "                traj_data.append(sorted(user_traj, key=lambda x: x[0]))\n",
    "        \n",
    "        return traj_data\n",
    "\n",
    "    def analyze_generated_trajectories(self, gen_df):\n",
    "        \"\"\"Analyze generated trajectory data\"\"\"\n",
    "        traj_data = []\n",
    "        \n",
    "        # Ensure timestamp column is in correct format\n",
    "        gen_df['datetime'] = gen_df['timestamp'].apply(self.parse_gen_time)\n",
    "        \n",
    "        # Remove records with invalid dates\n",
    "        gen_df = gen_df.dropna(subset=['datetime'])\n",
    "        \n",
    "        # Group trajectories by user and date\n",
    "        gen_df['date'] = gen_df['datetime'].apply(lambda x: x.strftime('%Y-%m-%d'))\n",
    "        \n",
    "        for (user_id, date), group in gen_df.groupby(['userId', 'date']):\n",
    "            user_traj = []\n",
    "            group = group.sort_values('datetime')\n",
    "            \n",
    "            for _, row in group.iterrows():\n",
    "                dt = row['datetime']\n",
    "                \n",
    "                # Process origin\n",
    "                origin_grid = self.latlon_to_grid(row['origin_lat'], row['origin_lon'])\n",
    "                if origin_grid >= 0:\n",
    "                    origin_act_id = self.get_activity_id(row['origin_category'])\n",
    "                    user_traj.append([dt, origin_act_id, [row['origin_lat'], row['origin_lon']]])\n",
    "                \n",
    "                # Process destination\n",
    "                dest_dt = dt + timedelta(minutes=10)  # Assume arrival is 10 minutes after departure\n",
    "                dest_grid = self.latlon_to_grid(row['destination_lat'], row['destination_lon'])\n",
    "                if dest_grid >= 0:\n",
    "                    dest_act_id = self.get_activity_id(row['destination_category'])\n",
    "                    user_traj.append([dest_dt, dest_act_id, [row['destination_lat'], row['destination_lon']]])\n",
    "            \n",
    "            if len(user_traj) > 1:\n",
    "                # Sort by time and remove duplicate points\n",
    "                user_traj = sorted(user_traj, key=lambda x: x[0])\n",
    "                # Remove points with identical time and location\n",
    "                filtered_traj = []\n",
    "                for i, point in enumerate(user_traj):\n",
    "                    if i == 0 or point[0] != user_traj[i-1][0] or point[2] != user_traj[i-1][2]:\n",
    "                        filtered_traj.append(point)\n",
    "                \n",
    "                if len(filtered_traj) > 1:\n",
    "                    traj_data.append(filtered_traj)\n",
    "        \n",
    "        return traj_data\n",
    "    \n",
    "    def calculate_distance_distribution(self, trajectories):\n",
    "        \"\"\"Calculate distance distribution between consecutive points in trajectories\"\"\"\n",
    "        distances = []\n",
    "        for traj in trajectories:\n",
    "            for i in range(len(traj) - 1):\n",
    "                curr_loc = traj[i][2]  # [lat, lon]\n",
    "                next_loc = traj[i+1][2]  # [lat, lon]\n",
    "                dist = geodistance(curr_loc[1], curr_loc[0], next_loc[1], next_loc[0])\n",
    "                if dist > 0:  # Exclude same location\n",
    "                    distances.append(dist)\n",
    "        return np.array(distances)\n",
    "    \n",
    "    def calculate_duration_distribution(self, trajectories):\n",
    "        \"\"\"Calculate stay duration distribution between consecutive points (in minutes)\"\"\"\n",
    "        durations = []\n",
    "        for traj in trajectories:\n",
    "            for i in range(len(traj) - 1):\n",
    "                # For real data, time is already datetime object\n",
    "                curr_time = traj[i][0]\n",
    "                next_time = traj[i+1][0]\n",
    "                \n",
    "                # Calculate time difference (minutes)\n",
    "                if isinstance(curr_time, datetime) and isinstance(next_time, datetime):\n",
    "                    # If datetime objects, calculate directly\n",
    "                    duration = (next_time - curr_time).total_seconds() / 60\n",
    "                else:\n",
    "                    # If still time slots, convert to minutes\n",
    "                    duration = (next_time - curr_time) * 10\n",
    "                \n",
    "                if duration > 0:  # Ignore non-positive values\n",
    "                    durations.append(duration)\n",
    "        \n",
    "        return np.array(durations)\n",
    "    \n",
    "    def calculate_activity_distribution(self, trajectories):\n",
    "        \"\"\"Calculate activity type distribution\"\"\"\n",
    "        # Initialize counters for all activity types\n",
    "        act_counts = np.zeros(len(self.activity_map))\n",
    "        \n",
    "        for traj in trajectories:\n",
    "            for point in traj:\n",
    "                act_id = point[1]\n",
    "                if 0 <= act_id < len(act_counts):\n",
    "                    act_counts[act_id] += 1\n",
    "        \n",
    "        return act_counts\n",
    "    \n",
    "    def calculate_location_distribution(self, trajectories):\n",
    "        \"\"\"Calculate spatial location distribution\"\"\"\n",
    "        loc_counts = np.zeros(self.grid_total)\n",
    "        \n",
    "        for traj in trajectories:\n",
    "            for point in traj:\n",
    "                lat, lon = point[2]\n",
    "                grid_idx = self.latlon_to_grid(lat, lon)\n",
    "                if grid_idx >= 0:\n",
    "                    loc_counts[grid_idx] += 1\n",
    "        \n",
    "        return loc_counts\n",
    "    \n",
    "    def calculate_st_activity_distribution(self, trajectories):\n",
    "        \"\"\"Calculate spatio-temporal activity distribution\"\"\"\n",
    "        # Create spatio-temporal activity indices\n",
    "        st_act_indices = []\n",
    "        \n",
    "        for traj in trajectories:\n",
    "            for point in traj:\n",
    "                time_bin, act_id = point[0], point[1]\n",
    "                st_act_indices.append(time_bin * 100 + act_id)  # Create unique index\n",
    "        \n",
    "        return np.array(st_act_indices)\n",
    "    \n",
    "    def calculate_st_location_distribution(self, trajectories):\n",
    "        \"\"\"Calculate spatio-temporal location distribution\"\"\"\n",
    "        # Create spatio-temporal location indices\n",
    "        st_loc_indices = []\n",
    "        \n",
    "        for traj in trajectories:\n",
    "            for point in traj:\n",
    "                time_bin = point[0]\n",
    "                lat, lon = point[2]\n",
    "                grid_idx = self.latlon_to_grid(lat, lon)\n",
    "                if grid_idx >= 0:\n",
    "                    st_loc_indices.append(time_bin * self.grid_total + grid_idx)  # Create unique index\n",
    "        \n",
    "        return np.array(st_loc_indices)\n",
    "    \n",
    "    def arr_to_distribution(self, arr, min_val, max_val, bins):\n",
    "        \"\"\"Convert array to distribution\"\"\"\n",
    "        if len(arr) == 0:\n",
    "            return np.zeros(bins)\n",
    "        \n",
    "        # Handle out-of-range values\n",
    "        in_range = arr[(arr >= min_val) & (arr <= max_val)]\n",
    "        out_range = arr[arr > max_val]\n",
    "        \n",
    "        # Calculate distribution\n",
    "        distribution, _ = np.histogram(in_range, bins=bins, range=(min_val, max_val))\n",
    "        \n",
    "        # Add out-of-range values to last bin\n",
    "        if len(out_range) > 0:\n",
    "            distribution = np.append(distribution, len(out_range))\n",
    "        else:\n",
    "            distribution = np.append(distribution, 0)  # Ensure consistent distribution length\n",
    "        \n",
    "        return distribution\n",
    "    \n",
    "    def calculate_jsd_metrics(self, real_trajectories, gen_trajectories):\n",
    "        \"\"\"Calculate JSD metrics\"\"\"\n",
    "        metrics = {}\n",
    "        \n",
    "        # 1. Movement distance distribution (SD)\n",
    "        real_distances = self.calculate_distance_distribution(real_trajectories)\n",
    "        gen_distances = self.calculate_distance_distribution(gen_trajectories)\n",
    "        \n",
    "        if len(real_distances) == 0 or len(gen_distances) == 0:\n",
    "            print(\"Warning: Insufficient distance data, cannot calculate SD metric\")\n",
    "            metrics['SD'] = np.nan\n",
    "        else:\n",
    "            # Distance range and number of bins\n",
    "            min_dist, max_dist = 0, max(np.percentile(real_distances, 95), np.percentile(gen_distances, 95))\n",
    "            dist_bins = 50\n",
    "            \n",
    "            real_dist_hist = self.arr_to_distribution(real_distances, min_dist, max_dist, dist_bins)\n",
    "            gen_dist_hist = self.arr_to_distribution(gen_distances, min_dist, max_dist, dist_bins)\n",
    "            \n",
    "            metrics['SD'] = js_divergence(real_dist_hist, gen_dist_hist)\n",
    "        \n",
    "        # 2. Stay duration distribution (SI)\n",
    "        real_durations = self.calculate_duration_distribution(real_trajectories)\n",
    "        gen_durations = self.calculate_duration_distribution(gen_trajectories)\n",
    "        \n",
    "        if len(real_durations) == 0 or len(gen_durations) == 0:\n",
    "            print(\"Warning: Insufficient duration data, cannot calculate SI metric\")\n",
    "            metrics['SI'] = np.nan\n",
    "        else:\n",
    "            # Time range and number of bins\n",
    "            min_dur, max_dur = 0, max(np.percentile(real_durations, 95), np.percentile(gen_durations, 95))\n",
    "            dur_bins = 50\n",
    "            \n",
    "            real_dur_hist = self.arr_to_distribution(real_durations, min_dur, max_dur, dur_bins)\n",
    "            gen_dur_hist = self.arr_to_distribution(gen_durations, min_dur, max_dur, dur_bins)\n",
    "            \n",
    "            metrics['SI'] = js_divergence(real_dur_hist, gen_dur_hist)\n",
    "        \n",
    "        # 3. Activity distribution (DARD)\n",
    "        real_acts = self.calculate_activity_distribution(real_trajectories)\n",
    "        gen_acts = self.calculate_activity_distribution(gen_trajectories)\n",
    "        \n",
    "        # Ensure both distributions have same length\n",
    "        max_len = max(len(real_acts), len(gen_acts))\n",
    "        if len(real_acts) < max_len:\n",
    "            real_acts = np.pad(real_acts, (0, max_len - len(real_acts)), 'constant')\n",
    "        if len(gen_acts) < max_len:\n",
    "            gen_acts = np.pad(gen_acts, (0, max_len - len(gen_acts)), 'constant')\n",
    "        \n",
    "        metrics['DARD'] = js_divergence(real_acts, gen_acts)\n",
    "        \n",
    "        # 4. Spatial location distribution (STVD)\n",
    "        real_locs = self.calculate_location_distribution(real_trajectories)\n",
    "        gen_locs = self.calculate_location_distribution(gen_trajectories)\n",
    "        \n",
    "        # Discard all-zero areas, keep only active grids\n",
    "        active_grids = np.logical_or(real_locs > 0, gen_locs > 0)\n",
    "        real_locs = real_locs[active_grids]\n",
    "        gen_locs = gen_locs[active_grids]\n",
    "        \n",
    "        if len(real_locs) == 0 or len(gen_locs) == 0:\n",
    "            print(\"Warning: Insufficient location data, cannot calculate STVD metric\")\n",
    "            metrics['STVD'] = np.nan\n",
    "        else:\n",
    "            metrics['STVD'] = js_divergence(real_locs, gen_locs)\n",
    "        \n",
    "        return metrics\n",
    "    \n",
    "    def print_trajectory_stats(self, trajectories, name):\n",
    "        \"\"\"Print trajectory statistics\"\"\"\n",
    "        if not trajectories:\n",
    "            print(f\"{name} dataset: No valid trajectories\")\n",
    "            return\n",
    "        \n",
    "        num_trajectories = len(trajectories)\n",
    "        total_points = sum(len(traj) for traj in trajectories)\n",
    "        avg_points_per_traj = total_points / num_trajectories\n",
    "        \n",
    "        # Calculate total distance\n",
    "        total_distance = 0\n",
    "        num_segments = 0\n",
    "        for traj in trajectories:\n",
    "            for i in range(len(traj) - 1):\n",
    "                curr_loc = traj[i][2]  # [lat, lon]\n",
    "                next_loc = traj[i+1][2]  # [lat, lon]\n",
    "                dist = geodistance(curr_loc[1], curr_loc[0], next_loc[1], next_loc[0])\n",
    "                total_distance += dist\n",
    "                num_segments += 1\n",
    "        \n",
    "        avg_distance = total_distance / max(num_segments, 1)\n",
    "        \n",
    "        # Count activity types\n",
    "        activity_counts = defaultdict(int)\n",
    "        for traj in trajectories:\n",
    "            for point in traj:\n",
    "                act_id = point[1]\n",
    "                activity_counts[act_id] += 1\n",
    "        \n",
    "        # Reverse lookup for activity names\n",
    "        act_id_to_name = {v: k for k, v in self.activity_map.items()}\n",
    "        top_activities = sorted(activity_counts.items(), key=lambda x: x[1], reverse=True)[:5]\n",
    "        \n",
    "        print(f\"{name} dataset statistics:\")\n",
    "        print(f\"  Number of trajectories: {num_trajectories}\")\n",
    "        print(f\"  Total points: {total_points}\")\n",
    "        print(f\"  Average points per trajectory: {avg_points_per_traj:.2f}\")\n",
    "        print(f\"  Average movement distance: {avg_distance:.2f} km\")\n",
    "        print(f\"  Most common activity types:\")\n",
    "        for act_id, count in top_activities:\n",
    "            act_name = act_id_to_name.get(act_id, f\"Unknown activity({act_id})\")\n",
    "            percentage = count / total_points * 100\n",
    "            print(f\"    - {act_name}: {count} times ({percentage:.1f}%)\")\n",
    "        print()\n",
    "\n",
    "def main(real_traj_path, gen_traj_path):\n",
    "    # Load data\n",
    "    real_df = pd.read_csv(real_traj_path)\n",
    "    gen_df = pd.read_csv(gen_traj_path)\n",
    "    \n",
    "    # Initialize analyzer\n",
    "    analyzer = TrajectoryAnalyzer(\n",
    "        grid_size=0.01,\n",
    "        lat_range=(40.5, 40.9),\n",
    "        lon_range=(-74.25, -73.7)\n",
    "    )\n",
    "    \n",
    "    # Analyze real trajectories\n",
    "    real_trajectories = analyzer.analyze_real_trajectories(real_df)\n",
    "    # print(f\"Analyzed real trajectories: {len(real_trajectories)} trajectories\")\n",
    "    analyzer.print_trajectory_stats(real_trajectories, \"Real\")\n",
    "    \n",
    "    # Analyze generated trajectories\n",
    "    gen_trajectories = analyzer.analyze_generated_trajectories(gen_df)\n",
    "    # print(f\"Analyzed generated trajectories: {len(gen_trajectories)} trajectories\")\n",
    "    analyzer.print_trajectory_stats(gen_trajectories, \"Generated\")\n",
    "    \n",
    "    # Calculate JSD metrics\n",
    "    metrics = analyzer.calculate_jsd_metrics(real_trajectories, gen_trajectories)\n",
    "    \n",
    "    # Print results\n",
    "    print(\"\\nTrajectory consistency analysis results (Jensen-Shannon Divergence):\")\n",
    "    print(f\"1. Step distance (SD): {metrics.get('SD', 'N/A'):.3f}\")\n",
    "    print(f\"2. Step interval (SI): {metrics.get('SI', 'N/A'):.3f}\")\n",
    "    print(f\"3. Daily activity routine distribution (DARD): {metrics.get('DARD', 'N/A'):.3f}\")\n",
    "    print(f\"4. Spatial-temporal visits distribution (STVD): {metrics.get('STVD', 'N/A'):.3f}\")\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # File path configuration\n",
    "    real_traj_path = r'D:\\A_Research\\A_doing_research\\20250526_LLM_causal_inference\\dataset\\dataset_TSMC2014_NYC.csv'\n",
    "    gen_traj_path = './output/generated_trajectories_w_p.csv'\n",
    "    \n",
    "    # Execute analysis\n",
    "    main(real_traj_path, gen_traj_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
