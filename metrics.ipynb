{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real Dataset Statistics:\n",
      "  Number of trajectories: 47322\n",
      "  Total points: 171040\n",
      "  Average points per trajectory: 3.61\n",
      "  Average movement distance: 3.18 km\n",
      "  Most common activity types:\n",
      "    - Food: 41431 times (24.2%)\n",
      "    - Shop & Service: 36634 times (21.4%)\n",
      "    - Travel & Transport: 27987 times (16.4%)\n",
      "    - Outdoors & Recreation: 18784 times (11.0%)\n",
      "    - Professional & Workplace: 14170 times (8.3%)\n",
      "\n",
      "Generated Dataset Statistics:\n",
      "  Number of trajectories: 1117\n",
      "  Total points: 20776\n",
      "  Average points per trajectory: 18.60\n",
      "  Average movement distance: 2.51 km\n",
      "  Most common activity types:\n",
      "    - Food: 6403 times (30.8%)\n",
      "    - Shop & Service: 4760 times (22.9%)\n",
      "    - Nightlife Spot: 2485 times (12.0%)\n",
      "    - Outdoors & Recreation: 2067 times (9.9%)\n",
      "    - Arts & Entertainment: 1212 times (5.8%)\n",
      "\n",
      "\n",
      "Trajectory Consistency Analysis Results (Jensen-Shannon Divergence):\n",
      "1. Step distance (SD): 0.039\n",
      "2. Step interval (SI): 0.292\n",
      "3. Daily activity routine distribution (DARD): 0.272\n",
      "4. Spatial-temporal visits distribution (STVD): 0.440\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "from datetime import datetime, timedelta\n",
    "from math import radians, sin, cos, asin, sqrt\n",
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "# Geographic distance calculation function (unit: kilometers)\n",
    "def geodistance(lon1, lat1, lon2, lat2):\n",
    "    lon1, lat1, lon2, lat2 = map(radians, [float(lon1), float(lat1), float(lon2), float(lat2)])\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\n",
    "    distance = 2 * asin(sqrt(a)) * 6371\n",
    "    return distance  # return kilometers\n",
    "\n",
    "# JSD calculation function\n",
    "def js_divergence(p, q):\n",
    "    p = np.array(p, dtype=float)\n",
    "    q = np.array(q, dtype=float)\n",
    "    \n",
    "    # Avoid division by zero\n",
    "    p = p / (p.sum() + 1e-9)\n",
    "    q = q / (q.sum() + 1e-9)\n",
    "    \n",
    "    m = (p + q) / 2\n",
    "    return 0.5 * scipy.stats.entropy(p, m) + 0.5 * scipy.stats.entropy(q, m)\n",
    "\n",
    "# Trajectory analysis class\n",
    "class TrajectoryAnalyzer:\n",
    "    def __init__(self, grid_size=0.01, lat_range=(40.5, 40.9), lon_range=(-74.25, -73.7)):\n",
    "        self.grid_size = grid_size\n",
    "        self.lat_min, self.lat_max = lat_range\n",
    "        self.lon_min, self.lon_max = lon_range\n",
    "        self.n_lat = int((self.lat_max - self.lat_min) / grid_size) + 1\n",
    "        self.n_lon = int((self.lon_max - self.lon_min) / grid_size) + 1\n",
    "        self.grid_total = self.n_lat * self.n_lon\n",
    "        self.time_bins = 144  # 24 hours * 6 (10-minute intervals)\n",
    "\n",
    "        self.category_keywords = {\n",
    "            'Food': [\n",
    "                'restaurant', 'food', 'cafe', 'coffee', 'deli', 'pizza', 'sandwich', \n",
    "                'burger', 'bakery', 'diner', 'donut', 'sushi', 'bagel', 'cream',\n",
    "                'bbq', 'seafood', 'thai', 'breakfast', 'dessert', 'japanese',\n",
    "                'caribbean', 'korean', 'chicken', 'indian', 'latin', 'steak',\n",
    "                'cuban', 'vegan', 'gastropub', 'ramen', 'noodle', 'burrito',\n",
    "                'hot dog', 'cupcake', 'spanish', 'tea', 'taco', 'salad',\n",
    "                'middle eastern', 'tapas', 'german', 'mediterranean', 'vietnamese',\n",
    "                'soup', 'soul', 'wings', 'greek', 'falafel', 'snack', 'brewery',\n",
    "                'brazilian', 'european', 'australian', 'molecular', 'dim sum',\n",
    "                'cajun', 'creole', 'dumpling', 'malaysian', 'african', 'filipino',\n",
    "                'mac & cheese', 'peruvian', 'argentinian', 'scandinavian', 'turkish',\n",
    "                'ethiopian', 'moroccan', 'swiss', 'fish', 'portuguese', 'distillery',\n",
    "                'gluten'\n",
    "            ],\n",
    "            \n",
    "            'Travel & Transport': [\n",
    "                'subway', 'station', 'transport', 'bus', 'road', 'airport', 'hotel',\n",
    "                'ferry', 'rail', 'parking', 'taxi', 'rental', 'lounge', 'bike share',\n",
    "                'train', 'commute', 'travel', 'walk', 'drive', 'truck', 'transport',\n",
    "                'bike', \n",
    "            ],\n",
    "            \n",
    "            'Shop & Service': [\n",
    "                'store', 'shop', 'clothing', 'drug', 'pharmacy', 'department',\n",
    "                'salon', 'barbershop', 'electronic', 'gas', 'garage', 'mall',\n",
    "                'laundry', 'book', 'convenience', 'automotive', 'furniture', 'home',\n",
    "                'cosmetic', 'hardware', 'sporting', 'pet', 'office', 'craft',\n",
    "                'flea', 'toy', 'game', 'smoke', 'candy', 'thrift', 'vintage',\n",
    "                'bike', 'gift', 'tattoo', 'video', 'jewelry', 'record', 'tanning',\n",
    "                'nail', 'phone', 'flower', 'bridal', 'hobby', 'camera', 'wash',\n",
    "                'dealership', 'antique', 'garden', 'board', 'newsstand', 'motorcycle'\n",
    "            ],\n",
    "            \n",
    "            'Nightlife Spot': [\n",
    "                'bar', 'beer garden', 'nightlife'\n",
    "            ],\n",
    "            \n",
    "            'Arts & Entertainment': [\n",
    "                'theater', 'movie', 'music', 'entertainment', 'performing',\n",
    "                'art', 'gallery', 'library', 'arcade', 'museum', 'concert',\n",
    "                'historic', 'bowling', 'comedy', 'casino', 'pool hall',\n",
    "                'winery', 'gaming', 'planetarium'\n",
    "            ],\n",
    "            \n",
    "            'Professional & Workplace': [\n",
    "                'office', 'building', 'medical', 'bank', 'government', 'church',\n",
    "                'post', 'city', 'moving', 'synagogue', 'design', 'factory',\n",
    "                'funeral', 'spiritual', 'work' , 'animal', 'temple', 'recycling',\n",
    "                'financial', 'legal', 'shrine', 'workplace', 'job', 'embassy', 'consulate',\n",
    "                'mosque', 'military', 'storage', 'internet', 'photography', 'service'\n",
    "            ],\n",
    "            \n",
    "            'Outdoors & Recreation': [\n",
    "                'gym', 'fitness', 'athletic', 'park', 'outdoors', 'bridge',\n",
    "                'plaza', 'stadium', 'beach', 'playground', 'scenic', 'harbor',\n",
    "                'marina', 'garden', 'campground', 'pool', 'cemetery', 'river',\n",
    "                'zoo', 'racetrack', 'ski', 'castle', 'aquarium'\n",
    "            ],\n",
    "            \n",
    "            'College & University': [\n",
    "                'college', 'school', 'university', 'academic', 'student',\n",
    "                'campus', 'fraternity', 'sorority', 'education'\n",
    "            ],\n",
    "            \n",
    "            'Residence': [\n",
    "                'home', 'residential', 'apartment', 'condo', 'neighborhood',\n",
    "                'housing'\n",
    "            ],\n",
    "            \n",
    "            'Event': [\n",
    "                'event', 'convention', 'market', 'fair'\n",
    "            ]\n",
    "        }\n",
    "\n",
    "        # Activity type ID mapping\n",
    "        self.activity_map = {\n",
    "            'Travel & Transport': 0,\n",
    "            'Food': 1, \n",
    "            'Shop & Service': 2,\n",
    "            'Nightlife Spot': 3,\n",
    "            'Arts & Entertainment': 4,\n",
    "            'Professional & Workplace': 5,\n",
    "            'Outdoors & Recreation': 6,\n",
    "            'College & University': 7,\n",
    "            'Residence': 8,\n",
    "            'Event': 9,\n",
    "            'Other': 10\n",
    "        }\n",
    "\n",
    "    def parse_real_time(self, time_str):\n",
    "        \"\"\"Parse real data time format (Tue Apr 03 18:00:09 +0000 2012)\"\"\"\n",
    "        try:\n",
    "            dt = datetime.strptime(time_str, '%a %b %d %H:%M:%S %z %Y')\n",
    "            return dt\n",
    "        except ValueError:\n",
    "            print(f\"Cannot parse real data time string: {time_str}\")\n",
    "            return None\n",
    "    \n",
    "    def parse_gen_time(self, time_str):\n",
    "        \"\"\"Parse generated data time format (2025/5/28 8:00)\"\"\"\n",
    "        try:\n",
    "            dt = datetime.strptime(time_str, '%Y/%m/%d %H:%M')\n",
    "            return dt\n",
    "        except ValueError:\n",
    "            try:\n",
    "                dt = datetime.strptime(time_str, '%Y-%m-%d %H:%M:%S')\n",
    "                return dt\n",
    "            except ValueError:\n",
    "                print(f\"Cannot parse generated data time string: {time_str}\")\n",
    "                return None\n",
    "    \n",
    "    def time_to_bin(self, dt):\n",
    "        \"\"\"Convert time to time interval index (10-minute intervals)\"\"\"\n",
    "        total_minutes = dt.hour * 60 + dt.minute\n",
    "        return min(int(total_minutes // 10), self.time_bins - 1)\n",
    "    \n",
    "    def latlon_to_grid(self, lat, lon):\n",
    "        \"\"\"Convert latitude and longitude to grid index\"\"\"\n",
    "        if not (self.lat_min <= lat <= self.lat_max and self.lon_min <= lon <= self.lon_max):\n",
    "            return -1  # Out of range\n",
    "        \n",
    "        lat_idx = int((lat - self.lat_min) / self.grid_size)\n",
    "        lon_idx = int((lon - self.lon_min) / self.grid_size)\n",
    "        return min(lat_idx * self.n_lon + lon_idx, self.grid_total - 1)\n",
    "\n",
    "    def normalize_category(self, category):\n",
    "        \"\"\"Normalize venue category\"\"\"\n",
    "        if not isinstance(category, str):\n",
    "            return 'Unknown'\n",
    "        \n",
    "        category_lower = f\" {category.lower()} \"\n",
    "        scores = {cat: 0 for cat in self.category_keywords.keys()}\n",
    "        \n",
    "        # Calculate matching score for each category\n",
    "        for main_category, keywords in self.category_keywords.items():\n",
    "            for keyword in keywords:\n",
    "                if f\" {keyword} \" in category_lower:\n",
    "                    scores[main_category] += 1\n",
    "        \n",
    "        # Return category with highest score\n",
    "        max_score = max(scores.values())\n",
    "        if max_score > 0:\n",
    "            return max(scores.items(), key=lambda x: x[1])[0]\n",
    "        \n",
    "        return 'Other'\n",
    "    \n",
    "    def get_activity_id(self, category):\n",
    "        \"\"\"Get activity type ID\"\"\"\n",
    "        normalized_category = self.normalize_category(category)\n",
    "        return self.activity_map.get(normalized_category, 5)  # Default to 'Professional & Other Places'\n",
    "\n",
    "    def analyze_real_trajectories(self, real_df):\n",
    "        \"\"\"Analyze real trajectory data\"\"\"\n",
    "        traj_data = []\n",
    "        \n",
    "        # Group trajectories by user and date\n",
    "        real_df['date'] = real_df['utcTimestamp'].apply(\n",
    "            lambda x: self.parse_real_time(x).strftime('%Y-%m-%d') if self.parse_real_time(x) else None\n",
    "        )\n",
    "        \n",
    "        # Remove records with invalid dates\n",
    "        real_df = real_df.dropna(subset=['date'])\n",
    "        \n",
    "        for (user_id, date), group in real_df.groupby(['userId', 'date']):\n",
    "            user_traj = []\n",
    "            group = group.sort_values('utcTimestamp')\n",
    "            \n",
    "            for _, row in group.iterrows():\n",
    "                dt = self.parse_real_time(row['utcTimestamp'])\n",
    "                if dt is None:\n",
    "                    continue\n",
    "                \n",
    "                grid_idx = self.latlon_to_grid(row['latitude'], row['longitude'])\n",
    "                \n",
    "                if grid_idx >= 0:\n",
    "                    # Store actual time instead of time interval\n",
    "                    act_id = self.get_activity_id(row['venueCategory'])\n",
    "                    user_traj.append([dt, act_id, [row['latitude'], row['longitude']]])\n",
    "            \n",
    "            if len(user_traj) > 1:\n",
    "                traj_data.append(sorted(user_traj, key=lambda x: x[0]))\n",
    "        \n",
    "        return traj_data\n",
    "\n",
    "    def analyze_generated_trajectories(self, gen_df):\n",
    "        \"\"\"Analyze generated trajectory data\"\"\"\n",
    "        traj_data = []\n",
    "        \n",
    "        # Ensure timestamp column format is correct\n",
    "        gen_df['datetime'] = gen_df['timestamp'].apply(self.parse_gen_time)\n",
    "        \n",
    "        # Remove records with invalid dates\n",
    "        gen_df = gen_df.dropna(subset=['datetime'])\n",
    "        \n",
    "        # Group trajectories by user and date\n",
    "        gen_df['date'] = gen_df['datetime'].apply(lambda x: x.strftime('%Y-%m-%d'))\n",
    "        \n",
    "        for (user_id, date), group in gen_df.groupby(['userId', 'date']):\n",
    "            user_traj = []\n",
    "            group = group.sort_values('datetime')\n",
    "            \n",
    "            for idx, row in group.iterrows():\n",
    "                dt = row['datetime']\n",
    "                \n",
    "                # Handle origin point\n",
    "                origin_grid = self.latlon_to_grid(row['origin_lat'], row['origin_lon'])\n",
    "                if origin_grid >= 0:\n",
    "                    origin_act_id = self.get_activity_id(row['origin_category'])\n",
    "                    user_traj.append([dt, origin_act_id, [row['origin_lat'], row['origin_lon']]])\n",
    "                \n",
    "                # Handle destination point\n",
    "                dest_dt = dt + timedelta(minutes=10)  # Assume arrival time is 10 minutes after departure\n",
    "                dest_grid = self.latlon_to_grid(row['destination_lat'], row['destination_lon'])\n",
    "                if dest_grid >= 0:\n",
    "                    dest_act_id = self.get_activity_id(row['destination_category'])\n",
    "                    user_traj.append([dest_dt, dest_act_id, [row['destination_lat'], row['destination_lon']]])\n",
    "                    \n",
    "                # If this is the last row, add the final destination point\n",
    "                if idx == group.index[-1]:\n",
    "                    final_dt = dest_dt + timedelta(minutes=10)  # Add additional time for the final destination\n",
    "                    if dest_grid >= 0:\n",
    "                        user_traj.append([final_dt, dest_act_id, [row['destination_lat'], row['destination_lon']]])\n",
    "            \n",
    "            if len(user_traj) > 1:\n",
    "                # Sort by time and remove duplicate points\n",
    "                user_traj = sorted(user_traj, key=lambda x: x[0])\n",
    "                # Remove points with same time and location\n",
    "                filtered_traj = []\n",
    "                for i, point in enumerate(user_traj):\n",
    "                    if i == 0 or point[0] != user_traj[i-1][0] or point[2] != user_traj[i-1][2]:\n",
    "                        filtered_traj.append(point)\n",
    "                \n",
    "                if len(filtered_traj) > 1:\n",
    "                    traj_data.append(filtered_traj)\n",
    "        \n",
    "        return traj_data\n",
    "\n",
    "    # def analyze_generated_trajectories(self, gen_df):\n",
    "    #     \"\"\"Analyze generated trajectory data\"\"\"\n",
    "    #     traj_data = []\n",
    "        \n",
    "    #     # Ensure timestamp columns format is correct\n",
    "    #     gen_df['arrival_time'] = gen_df['times_arr'].apply(self.parse_gen_time)\n",
    "    #     gen_df['departure_time'] = gen_df['time_dep'].apply(self.parse_gen_time)\n",
    "        \n",
    "    #     # Remove records with invalid dates\n",
    "    #     gen_df = gen_df.dropna(subset=['arrival_time', 'departure_time'])\n",
    "        \n",
    "    #     # Group trajectories by user and date\n",
    "    #     gen_df['date'] = gen_df['arrival_time'].apply(lambda x: x.strftime('%Y-%m-%d'))\n",
    "        \n",
    "    #     for (user_id, date), group in gen_df.groupby(['userId', 'date']):\n",
    "    #         user_traj = []\n",
    "    #         group = group.sort_values('arrival_time')\n",
    "            \n",
    "    #         for idx, row in group.iterrows():\n",
    "    #             # Handle point with arrival time\n",
    "    #             origin_grid = self.latlon_to_grid(row['origin_lat'], row['origin_lon'])\n",
    "    #             if origin_grid >= 0:\n",
    "    #                 origin_act_id = self.get_activity_id(row['origin_category'])\n",
    "    #                 # Add point with arrival time\n",
    "    #                 user_traj.append([row['arrival_time'], origin_act_id, \n",
    "    #                                 [row['origin_lat'], row['origin_lon']]])\n",
    "                    \n",
    "    #                 # Add the same point with departure time\n",
    "    #                 user_traj.append([row['departure_time'], origin_act_id, \n",
    "    #                                 [row['origin_lat'], row['origin_lon']]])\n",
    "                \n",
    "    #             # If this is the last row, add the final destination point\n",
    "    #             if idx == group.index[-1]:\n",
    "    #                 dest_grid = self.latlon_to_grid(row['destination_lat'], row['destination_lon'])\n",
    "    #                 if dest_grid >= 0:\n",
    "    #                     dest_act_id = self.get_activity_id(row['destination_category'])\n",
    "    #                     user_traj.append([row['departure_time'], \n",
    "    #                                     dest_act_id, \n",
    "    #                                     [row['destination_lat'], row['destination_lon']]])\n",
    "            \n",
    "    #         if len(user_traj) > 1:\n",
    "    #             # Sort by time and remove duplicate points\n",
    "    #             user_traj = sorted(user_traj, key=lambda x: x[0])\n",
    "                \n",
    "    #             # Remove points with same time and location\n",
    "    #             filtered_traj = []\n",
    "    #             for i, point in enumerate(user_traj):\n",
    "    #                 if i == 0 or point[0] != user_traj[i-1][0] or point[2] != user_traj[i-1][2]:\n",
    "    #                     filtered_traj.append(point)\n",
    "                \n",
    "    #             if len(filtered_traj) > 1:\n",
    "    #                 traj_data.append(filtered_traj)\n",
    "        \n",
    "    #     return traj_data\n",
    "    \n",
    "    def calculate_distance_distribution(self, trajectories):\n",
    "        \"\"\"Calculate distance distribution between consecutive points\"\"\"\n",
    "        distances = []\n",
    "        for traj in trajectories:\n",
    "            for i in range(len(traj) - 1):\n",
    "                curr_loc = traj[i][2]  # [lat, lon]\n",
    "                next_loc = traj[i+1][2]  # [lat, lon]\n",
    "                dist = geodistance(curr_loc[1], curr_loc[0], next_loc[1], next_loc[0])\n",
    "                if dist > 0:  # Exclude same locations\n",
    "                    distances.append(dist)\n",
    "        return np.array(distances)\n",
    "    \n",
    "    def calculate_duration_distribution(self, trajectories):\n",
    "        \"\"\"Calculate stay duration distribution between consecutive points (minutes)\"\"\"\n",
    "        durations = []\n",
    "        for traj in trajectories:\n",
    "            for i in range(len(traj) - 1):\n",
    "                # For real data, time is already datetime object\n",
    "                curr_time = traj[i][0]\n",
    "                next_time = traj[i+1][0]\n",
    "                \n",
    "                # Calculate time difference (minutes)\n",
    "                if isinstance(curr_time, datetime) and isinstance(next_time, datetime):\n",
    "                    # If datetime objects, calculate directly\n",
    "                    duration = (next_time - curr_time).total_seconds() / 60\n",
    "                else:\n",
    "                    # If still time intervals, convert to minutes\n",
    "                    duration = (next_time - curr_time) * 10\n",
    "                \n",
    "                if duration > 0:  # Ignore non-positive values\n",
    "                    durations.append(duration)\n",
    "        \n",
    "        return np.array(durations)\n",
    "    \n",
    "    def calculate_activity_distribution(self, trajectories):\n",
    "        \"\"\"Calculate activity type distribution\"\"\"\n",
    "        # Initialize counters for all activity types\n",
    "        act_counts = np.zeros(len(self.activity_map))\n",
    "        \n",
    "        for traj in trajectories:\n",
    "            for point in traj:\n",
    "                act_id = point[1]\n",
    "                if 0 <= act_id < len(act_counts):\n",
    "                    act_counts[act_id] += 1\n",
    "        \n",
    "        return act_counts\n",
    "    \n",
    "    def calculate_location_distribution(self, trajectories):\n",
    "        \"\"\"Calculate spatial location distribution\"\"\"\n",
    "        loc_counts = np.zeros(self.grid_total)\n",
    "        \n",
    "        for traj in trajectories:\n",
    "            for point in traj:\n",
    "                lat, lon = point[2]\n",
    "                grid_idx = self.latlon_to_grid(lat, lon)\n",
    "                if grid_idx >= 0:\n",
    "                    loc_counts[grid_idx] += 1\n",
    "        \n",
    "        return loc_counts\n",
    "    \n",
    "    def calculate_st_activity_distribution(self, trajectories):\n",
    "        \"\"\"Calculate spatio-temporal activity distribution (reference st_act_jsd in code)\"\"\"\n",
    "        st_act_dict = {}\n",
    "        indices = []\n",
    "        \n",
    "        # Build unified spatio-temporal activity dictionary\n",
    "        for traj in trajectories:\n",
    "            for point in traj:\n",
    "                dt, act_id, _ = point\n",
    "                time_bin = self.time_to_bin(dt)\n",
    "                key = (time_bin, act_id)\n",
    "                if key not in st_act_dict:\n",
    "                    st_act_dict[key] = len(st_act_dict)\n",
    "                indices.append(st_act_dict[key])\n",
    "        \n",
    "        return np.array(indices)\n",
    "    \n",
    "    def calculate_st_location_distribution(self, trajectories):\n",
    "        \"\"\"Calculate spatio-temporal location distribution (reference st_loc_jsd in code)\"\"\"\n",
    "        st_loc_dict = {}\n",
    "        indices = []\n",
    "        \n",
    "        # Build unified spatio-temporal location dictionary\n",
    "        for traj in trajectories:\n",
    "            for point in traj:\n",
    "                dt, _, loc = point\n",
    "                time_bin = self.time_to_bin(dt)\n",
    "                grid_idx = self.latlon_to_grid(loc[0], loc[1])\n",
    "                if grid_idx < 0:  # Skip invalid locations\n",
    "                    continue\n",
    "                key = (time_bin, grid_idx)\n",
    "                if key not in st_loc_dict:\n",
    "                    st_loc_dict[key] = len(st_loc_dict)\n",
    "                indices.append(st_loc_dict[key])\n",
    "        \n",
    "        return np.array(indices)\n",
    "    \n",
    "    def calculate_jsd_with_bins(self, real_arr, gen_arr, min_val, max_val, bins, total_bins=None):\n",
    "        \"\"\"Unified JSD calculation logic (consistent with reference code)\"\"\"\n",
    "        # Normalization\n",
    "        if total_bins is not None and len(real_arr) > 0 and len(gen_arr) > 0:\n",
    "            min_idx = min(np.min(real_arr), np.min(gen_arr))\n",
    "            max_idx = max(np.max(real_arr), np.max(gen_arr))\n",
    "            real_arr = (real_arr - min_idx) / (max_idx - min_idx + 1e-9)\n",
    "            gen_arr = (gen_arr - min_idx) / (max_idx - min_idx + 1e-9)\n",
    "            min_val, max_val = 0, 1\n",
    "        \n",
    "        # Bin statistics\n",
    "        real_hist, _ = np.histogram(real_arr, bins=bins, range=(min_val, max_val))\n",
    "        gen_hist, _ = np.histogram(gen_arr, bins=bins, range=(min_val, max_val))\n",
    "        \n",
    "        # Handle out-of-range values\n",
    "        real_out = len(real_arr[real_arr > max_val])\n",
    "        gen_out = len(gen_arr[gen_arr > max_val])\n",
    "        \n",
    "        real_hist = np.append(real_hist, real_out)\n",
    "        gen_hist = np.append(gen_hist, gen_out)\n",
    "        \n",
    "        return js_divergence(real_hist, gen_hist)\n",
    "    \n",
    "    def arr_to_distribution(self, arr, min_val, max_val, bins):\n",
    "        \"\"\"Convert array to distribution\"\"\"\n",
    "        if len(arr) == 0:\n",
    "            return np.zeros(bins)\n",
    "        \n",
    "        # Handle out-of-range values\n",
    "        in_range = arr[(arr >= min_val) & (arr <= max_val)]\n",
    "        out_range = arr[arr > max_val]\n",
    "        \n",
    "        # Calculate distribution\n",
    "        distribution, _ = np.histogram(in_range, bins=bins, range=(min_val, max_val))\n",
    "        \n",
    "        # Add out-of-range values to last bin\n",
    "        if len(out_range) > 0:\n",
    "            distribution = np.append(distribution, len(out_range))\n",
    "        else:\n",
    "            distribution = np.append(distribution, 0)  # Ensure consistent distribution length\n",
    "        \n",
    "        return distribution\n",
    "\n",
    "    def calculate_jsd_metrics(self, real_trajectories, gen_trajectories):\n",
    "        \"\"\"Calculate JSD metrics (consistent with reference code parameters)\"\"\"\n",
    "        metrics = {}\n",
    "        \n",
    "        # 1. Step distance (SD) - 0-10 km, 10 bins\n",
    "        real_distances = self.calculate_distance_distribution(real_trajectories)\n",
    "        gen_distances = self.calculate_distance_distribution(gen_trajectories)\n",
    "        metrics['SD'] = self.calculate_jsd_with_bins(real_distances, gen_distances, 0, 10, 10)\n",
    "        \n",
    "        # 2. Step interval (SI) - Convert to 10-minute intervals, 0-12 intervals, 12 bins\n",
    "        real_durations = self.calculate_duration_distribution(real_trajectories)\n",
    "        gen_durations = self.calculate_duration_distribution(gen_trajectories)\n",
    "        \n",
    "        if len(real_durations) == 0 or len(gen_durations) == 0:\n",
    "            print(\"Warning: Insufficient duration data, cannot calculate SI metric\")\n",
    "            metrics['SI'] = np.nan\n",
    "        else:\n",
    "            # Time range and number of bins\n",
    "            min_dur, max_dur = 0, max(np.percentile(real_durations, 95), np.percentile(gen_durations, 95))\n",
    "            dur_bins = 50\n",
    "            \n",
    "            real_dur_hist = self.arr_to_distribution(real_durations, min_dur, max_dur, dur_bins)\n",
    "            gen_dur_hist = self.arr_to_distribution(gen_durations, min_dur, max_dur, dur_bins)\n",
    "            \n",
    "            metrics['SI'] = js_divergence(real_dur_hist, gen_dur_hist)\n",
    "        \n",
    "        # 3. Daily activity routine distribution (DARD) - 1000 bins\n",
    "        real_st_act = self.calculate_st_activity_distribution(real_trajectories)\n",
    "        gen_st_act = self.calculate_st_activity_distribution(gen_trajectories)\n",
    "        metrics['DARD'] = self.calculate_jsd_with_bins(real_st_act, gen_st_act, 0, 1, 1000, total_bins=True)\n",
    "        \n",
    "        # 4. Spatial-temporal visits distribution (STVD) - 400 bins\n",
    "        real_st_loc = self.calculate_st_location_distribution(real_trajectories)\n",
    "        gen_st_loc = self.calculate_st_location_distribution(gen_trajectories)\n",
    "        metrics['STVD'] = self.calculate_jsd_with_bins(real_st_loc, gen_st_loc, 0, 1, 400, total_bins=True)\n",
    "        \n",
    "        return metrics\n",
    "    \n",
    "    def print_trajectory_stats(self, trajectories, name):\n",
    "        \"\"\"Print trajectory statistics\"\"\"\n",
    "        if not trajectories:\n",
    "            print(f\"{name} dataset: No valid trajectories\")\n",
    "            return\n",
    "        \n",
    "        num_trajectories = len(trajectories)\n",
    "        total_points = sum(len(traj) for traj in trajectories)\n",
    "        avg_points_per_traj = total_points / num_trajectories\n",
    "        \n",
    "        # Calculate total distance\n",
    "        total_distance = 0\n",
    "        num_segments = 0\n",
    "        for traj in trajectories:\n",
    "            for i in range(len(traj) - 1):\n",
    "                curr_loc = traj[i][2]  # [lat, lon]\n",
    "                next_loc = traj[i+1][2]  # [lat, lon]\n",
    "                dist = geodistance(curr_loc[1], curr_loc[0], next_loc[1], next_loc[0])\n",
    "                total_distance += dist\n",
    "                num_segments += 1\n",
    "        \n",
    "        avg_distance = total_distance / max(num_segments, 1)\n",
    "        \n",
    "        # Activity type statistics\n",
    "        activity_counts = defaultdict(int)\n",
    "        for traj in trajectories:\n",
    "            for point in traj:\n",
    "                act_id = point[1]\n",
    "                activity_counts[act_id] += 1\n",
    "        \n",
    "        # Reverse mapping from activity ID to name\n",
    "        act_id_to_name = {v: k for k, v in self.activity_map.items()}\n",
    "        top_activities = sorted(activity_counts.items(), key=lambda x: x[1], reverse=True)[:5]\n",
    "        \n",
    "        print(f\"{name} Dataset Statistics:\")\n",
    "        print(f\"  Number of trajectories: {num_trajectories}\")\n",
    "        print(f\"  Total points: {total_points}\")\n",
    "        print(f\"  Average points per trajectory: {avg_points_per_traj:.2f}\")\n",
    "        print(f\"  Average movement distance: {avg_distance:.2f} km\")\n",
    "        print(f\"  Most common activity types:\")\n",
    "        for act_id, count in top_activities:\n",
    "            act_name = act_id_to_name.get(act_id, f\"Unknown activity({act_id})\")\n",
    "            percentage = count / total_points * 100\n",
    "            print(f\"    - {act_name}: {count} times ({percentage:.1f}%)\")\n",
    "        print()\n",
    "\n",
    "def main(real_traj_path, gen_traj_path):\n",
    "    # Load data\n",
    "    real_df = pd.read_csv(real_traj_path)\n",
    "    gen_df = pd.read_csv(gen_traj_path)\n",
    "\n",
    "    # analyzer = TrajectoryAnalyzer(\n",
    "    #     grid_size=0.01,\n",
    "    #     lat_range=(40.5, 40.9),  # New York latitude range\n",
    "    #     lon_range=(-74.25, -73.7)  # New York latitude range\n",
    "    # )\n",
    "    \n",
    "    # Initialize analyzer (using New York range)\n",
    "    analyzer = TrajectoryAnalyzer(\n",
    "        grid_size=0.001,\n",
    "        lat_range=(40.5, 40.9),  # New York latitude range\n",
    "        lon_range=(-74.25, -73.7)  # New York longitude range\n",
    "    )\n",
    "    \n",
    "    # Analyze real trajectories\n",
    "    real_trajectories = analyzer.analyze_real_trajectories(real_df)\n",
    "    analyzer.print_trajectory_stats(real_trajectories, \"Real\")\n",
    "    \n",
    "    # Analyze generated trajectories\n",
    "    gen_trajectories = analyzer.analyze_generated_trajectories(gen_df)\n",
    "    analyzer.print_trajectory_stats(gen_trajectories, \"Generated\")\n",
    "    \n",
    "    # Calculate JSD metrics\n",
    "    metrics = analyzer.calculate_jsd_metrics(real_trajectories, gen_trajectories)\n",
    "    \n",
    "    # Print results\n",
    "    print(\"\\nTrajectory Consistency Analysis Results (Jensen-Shannon Divergence):\")\n",
    "    print(f\"1. Step distance (SD): {metrics.get('SD', 'N/A'):.3f}\")\n",
    "    print(f\"2. Step interval (SI): {metrics.get('SI', 'N/A'):.3f}\")\n",
    "    print(f\"3. Daily activity routine distribution (DARD): {metrics.get('DARD', 'N/A'):.3f}\")\n",
    "    print(f\"4. Spatial-temporal visits distribution (STVD): {metrics.get('STVD', 'N/A'):.3f}\")\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # File path configuration\n",
    "    real_traj_path = './dataset/dataset_TSMC2014_NYC.csv'\n",
    "    gen_traj_path = './output/generated_trajectories_CoT.csv'\n",
    "    # gen_traj_path = r'D:\\A_Research\\A_doing_research\\20250526_LLM_causal_inference\\output_results\\generated_trajectories_gpt4o.csv'\n",
    "    \n",
    "    # Execute analysis\n",
    "    main(real_traj_path, gen_traj_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
